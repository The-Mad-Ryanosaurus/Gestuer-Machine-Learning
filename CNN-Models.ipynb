{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning: Convolutional Neural Network Gesture Models**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Ryan Harte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [CNN: Project Setup](#cnn-project-setup)\n",
    "3. [CNN Model: Light from Scratch](#cnn-model-light-from-scratch)\n",
    "4. [CNN Model: Deep from Scratch](#cnn-model-deep-from-scratch)\n",
    "5. [CNN Model: Data Augmentation](#cnn-model-data-augmentation)\n",
    "6. [CNN Model: Data Augmentation Fine Tuned](#cnn-model-data-augmentation-fine-tuned)\n",
    "7. [CNN Model: Grayscale](#cnn-model-grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "This repository features a Jupyter Notebook that explores Convolutional Neural Networks (CNNs) in machine learning. The notebook analyzes a comprehensive dataset of images depicting human hand gestures and training a Neural Network (NN) to accurately recognize them. It is then tested on images of my own hand gestures to assess the NN ability to identify them correctly. The project also includes an evaluation of the model's accuracy and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN: Project Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, applications\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import RandomZoom, RandomRotation, RandomFlip, Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "\n",
    "# Suppress warnings from the logging module\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow Version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: 1\n"
     ]
    }
   ],
   "source": [
    "# Check if any GPU devices are detected\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detected: {len(gpus)}\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Set seed\n",
    "SEED = 338424\n",
    "\n",
    "# Global variables\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "num_classes = 18 # Number of folders in dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset: Loading, Splitting and Shuffling the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125912 files belonging to 18 classes.\n",
      "Using 88128 samples in the Training set\n",
      "Using 25184 samples in the Validation set\n",
      "Using 12600 samples in the Test set\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "dataset_dir = 'dataset/hagridset'\n",
    "full_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Total length of the dataset\n",
    "total_size = len(full_ds)\n",
    "\n",
    "# Compute indices for the splits\n",
    "train_size = int(total_size * train_ratio)\n",
    "val_size = int(total_size * val_ratio)\n",
    "test_size = total_size - (train_size + val_size)\n",
    "\n",
    "# Split the dataset and shuffle\n",
    "train_ds = full_ds.take(train_size).shuffle(train_size, seed=SEED)\n",
    "val_ds = full_ds.skip(train_size).take(val_size).shuffle(val_size, seed=SEED)\n",
    "test_ds = full_ds.skip(train_size + val_size).shuffle(test_size, seed=SEED)\n",
    "\n",
    "# Cache the dataset in memory (or use a directory to store it on disk if necessary)\n",
    "train_ds = full_ds.take(train_size).shuffle(train_size, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = full_ds.skip(train_size).take(val_size).shuffle(val_size, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = full_ds.skip(train_size + val_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Count samples in each subset\n",
    "def count_samples(dataset):\n",
    "    sample_count = sum(1 for _ in dataset.unbatch())\n",
    "    return sample_count\n",
    "\n",
    "# Output the number of samples for each dataset\n",
    "print(f'Using {count_samples(train_ds)} samples in the Training set')\n",
    "print(f'Using {count_samples(val_ds)} samples in the Validation set')\n",
    "print(f'Using {count_samples(test_ds)} samples in the Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = 'savedDataset'\n",
    "\n",
    "tf.data.experimental.save(train_ds, path_to_save + '/train')\n",
    "tf.data.experimental.save(val_ds, path_to_save + '/val')\n",
    "tf.data.experimental.save(test_ds, path_to_save + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'dislike',\n",
       " 'fist',\n",
       " 'four',\n",
       " 'like',\n",
       " 'mute',\n",
       " 'ok',\n",
       " 'one',\n",
       " 'palm',\n",
       " 'peace',\n",
       " 'peace_inverted',\n",
       " 'rock',\n",
       " 'stop',\n",
       " 'stop_inverted',\n",
       " 'three',\n",
       " 'three2',\n",
       " 'two_up',\n",
       " 'two_up_inverted']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names\n",
    "class_names = full_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Model: Light from Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                147474    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241,362\n",
      "Trainable params: 241,042\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Light CNN Model from Scratch\n",
    "def build_scratch_cnn_light():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu')) \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))  \n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))  \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the lighter model\n",
    "scratch_model_light = build_scratch_cnn_light()\n",
    "scratch_model_light.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754/2754 [==============================] - 22s 8ms/step - loss: 2.7768 - accuracy: 0.2348 - val_loss: 2.2440 - val_accuracy: 0.3252\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 21s 8ms/step - loss: 1.8417 - accuracy: 0.4150 - val_loss: 1.5863 - val_accuracy: 0.4792\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 1.4732 - accuracy: 0.5254 - val_loss: 1.2721 - val_accuracy: 0.5860\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 1.2346 - accuracy: 0.6004 - val_loss: 0.9905 - val_accuracy: 0.6895\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 22s 8ms/step - loss: 1.0857 - accuracy: 0.6495 - val_loss: 1.0082 - val_accuracy: 0.6798\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 21s 8ms/step - loss: 0.9952 - accuracy: 0.6780 - val_loss: 0.8479 - val_accuracy: 0.7361\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 0.9265 - accuracy: 0.7018 - val_loss: 0.8053 - val_accuracy: 0.7521\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 0.8710 - accuracy: 0.7164 - val_loss: 0.7412 - val_accuracy: 0.7708\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 0.8318 - accuracy: 0.7304 - val_loss: 0.7201 - val_accuracy: 0.7807\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 20s 7ms/step - loss: 0.7970 - accuracy: 0.7417 - val_loss: 0.6843 - val_accuracy: 0.7893\n"
     ]
    }
   ],
   "source": [
    "# Train Light CNN Model\n",
    "history_light = scratch_model_light.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in history_light.history.keys():\n",
    "    history_light.history[key] = [float(i) for i in history_light.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_light.json', 'w') as f:\n",
    "    json.dump(history_light.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Light Model: Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "scratch_model_light.save('scratch_model_light.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "scratch_model_light = load_model('scratch_model_light.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Model: Deep from Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307,634\n",
      "Trainable params: 306,738\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Deep CNN Model from Scratch\n",
    "def build_scratch_cnn_deep():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5)) \n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "scratch_model_deep = build_scratch_cnn_deep()\n",
    "scratch_model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754/2754 [==============================] - 46s 14ms/step - loss: 2.7485 - accuracy: 0.1664 - val_loss: 2.1669 - val_accuracy: 0.3690\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 26s 10ms/step - loss: 1.7113 - accuracy: 0.5246 - val_loss: 1.3279 - val_accuracy: 0.6680\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 26s 10ms/step - loss: 1.2757 - accuracy: 0.6900 - val_loss: 1.0479 - val_accuracy: 0.7620\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 27s 10ms/step - loss: 1.1041 - accuracy: 0.7467 - val_loss: 0.9391 - val_accuracy: 0.7982\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 27s 10ms/step - loss: 1.0005 - accuracy: 0.7807 - val_loss: 1.0724 - val_accuracy: 0.7623\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 26s 10ms/step - loss: 0.9396 - accuracy: 0.7986 - val_loss: 0.9228 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 26s 10ms/step - loss: 0.8776 - accuracy: 0.8195 - val_loss: 0.8942 - val_accuracy: 0.8110\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 27s 10ms/step - loss: 0.8424 - accuracy: 0.8301 - val_loss: 1.0492 - val_accuracy: 0.7753\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 27s 10ms/step - loss: 0.8095 - accuracy: 0.8389 - val_loss: 0.9635 - val_accuracy: 0.7922\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 27s 10ms/step - loss: 0.7808 - accuracy: 0.8469 - val_loss: 0.9568 - val_accuracy: 0.7982\n"
     ]
    }
   ],
   "source": [
    "# Train Deep CNN Model\n",
    "history_deep = scratch_model_deep.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in history_deep.history.keys():\n",
    "    history_deep.history[key] = [float(i) for i in history_deep.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_deep.json', 'w') as f:\n",
    "    json.dump(history_deep.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Deep Model: Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "scratch_model_deep.save('scratch_model_deep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "scratch_model_deep = load_model('scratch_model_deep.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Model: Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation_layers = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_6 (Sequential)   (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " rescaling_5 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307,634\n",
      "Trainable params: 306,738\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Deep CNN Model from Scratch\n",
    "def build_scratch_cnn_da():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    model.add(data_augmentation_layers)\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "   \n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5)) \n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "scratch_model_da = build_scratch_cnn_da()\n",
    "scratch_model_da.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2754/2754 [==============================] - 451s 163ms/step - loss: 2.8682 - accuracy: 0.1280 - val_loss: 2.2481 - val_accuracy: 0.3042\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 527s 191ms/step - loss: 2.0021 - accuracy: 0.4070 - val_loss: 1.6024 - val_accuracy: 0.5705\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 311s 113ms/step - loss: 1.5182 - accuracy: 0.6055 - val_loss: 1.1555 - val_accuracy: 0.7275\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 309s 112ms/step - loss: 1.3078 - accuracy: 0.6843 - val_loss: 1.0098 - val_accuracy: 0.7791\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 324s 118ms/step - loss: 1.1945 - accuracy: 0.7219 - val_loss: 0.9408 - val_accuracy: 0.7984\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 310s 112ms/step - loss: 1.1172 - accuracy: 0.7462 - val_loss: 0.9711 - val_accuracy: 0.7854\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 310s 113ms/step - loss: 1.0651 - accuracy: 0.7613 - val_loss: 0.8926 - val_accuracy: 0.8108\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 313s 114ms/step - loss: 1.0166 - accuracy: 0.7771 - val_loss: 0.8671 - val_accuracy: 0.8177\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 309s 112ms/step - loss: 0.9945 - accuracy: 0.7820 - val_loss: 0.9734 - val_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 311s 113ms/step - loss: 0.9683 - accuracy: 0.7924 - val_loss: 0.8268 - val_accuracy: 0.8292\n"
     ]
    }
   ],
   "source": [
    "# Train Deep CNN Model\n",
    "history_da = scratch_model_da.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in history_da.history.keys():\n",
    "    history_da.history[key] = [float(i) for i in history_da.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_da.json', 'w') as f:\n",
    "    json.dump(history_da.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Data Augmentation Model: Save and Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "scratch_model_da.save('scratch_model_da.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "scratch_model_da = load_model('scratch_model_da.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Model: Data Augmentation Fine-Tuned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_6 (Sequential)   (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " rescaling_6 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,122\n",
      "Trainable params: 290,226\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Deep CNN Model from Scratch\n",
    "def build_scratch_model_da_adapted_cnn():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    model.add(data_augmentation_layers)\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "   \n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "scratch_model_da_adapted = build_scratch_model_da_adapted_cnn()\n",
    "scratch_model_da_adapted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754/2754 [==============================] - 601s 215ms/step - loss: 1.6664 - accuracy: 0.4671 - val_loss: 1.1762 - val_accuracy: 0.6170\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 370s 135ms/step - loss: 0.8278 - accuracy: 0.7325 - val_loss: 0.6399 - val_accuracy: 0.7952\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 312s 113ms/step - loss: 0.6425 - accuracy: 0.7933 - val_loss: 0.6069 - val_accuracy: 0.8062\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 315s 114ms/step - loss: 0.5419 - accuracy: 0.8256 - val_loss: 0.4798 - val_accuracy: 0.8446\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 306s 111ms/step - loss: 0.4762 - accuracy: 0.8459 - val_loss: 0.5335 - val_accuracy: 0.8276\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 304s 111ms/step - loss: 0.4341 - accuracy: 0.8587 - val_loss: 0.5785 - val_accuracy: 0.8154\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 303s 110ms/step - loss: 0.3924 - accuracy: 0.8722 - val_loss: 0.4652 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 306s 111ms/step - loss: 0.3613 - accuracy: 0.8820 - val_loss: 0.4336 - val_accuracy: 0.8643\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 306s 111ms/step - loss: 0.3361 - accuracy: 0.8906 - val_loss: 0.4141 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 307s 112ms/step - loss: 0.3179 - accuracy: 0.8963 - val_loss: 0.4700 - val_accuracy: 0.8495\n"
     ]
    }
   ],
   "source": [
    "# Train Deep CNN Model\n",
    "history_da_adapted = scratch_model_da_adapted.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in history_da_adapted.history.keys():\n",
    "    history_da_adapted.history[key] = [float(i) for i in history_da_adapted.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_da_adapted.json', 'w') as f:\n",
    "    json.dump(history_da_adapted.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Data Augmentation Model Adapted: Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "scratch_model_da_adapted.save('scratch_model_da_adapted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "scratch_model_da_adapted = load_model('scratch_model_da_adapted.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Model: Grayscale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125912 files belonging to 18 classes.\n",
      "Using 88128 samples in the Grayscale Training set\n",
      "Using 25184 samples in the Grayscale Validation set\n",
      "Using 12600 samples in the Grayscale Test set\n"
     ]
    }
   ],
   "source": [
    "# Load the grayscale dataset separately\n",
    "full_ds_grayscale = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale'  # Load images in grayscale mode\n",
    ")\n",
    "\n",
    "# Split the grayscale dataset into training, validation, and test sets\n",
    "train_size_grayscale = int(train_ratio * len(full_ds_grayscale))\n",
    "val_size_grayscale = int(val_ratio * len(full_ds_grayscale))\n",
    "test_size_grayscale = len(full_ds_grayscale) - (train_size_grayscale + val_size_grayscale)\n",
    "\n",
    "# Shuffle and cache the grayscale datasets\n",
    "train_ds_grayscale = (full_ds_grayscale.take(train_size_grayscale).shuffle(train_size_grayscale, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE))\n",
    "val_ds_grayscale = (full_ds_grayscale.skip(train_size_grayscale).take(val_size_grayscale).shuffle(val_size_grayscale, seed=SEED).cache().prefetch(buffer_size=AUTOTUNE))\n",
    "test_ds_grayscale = (full_ds_grayscale.skip(train_size_grayscale + val_size_grayscale).cache().prefetch(buffer_size=AUTOTUNE))\n",
    "\n",
    "# Count samples in each grayscale subset\n",
    "def count_samples(dataset):\n",
    "    sample_count = sum(1 for _ in dataset.unbatch())\n",
    "    return sample_count\n",
    "\n",
    "# Output the number of samples for each grayscale dataset\n",
    "print(f'Using {count_samples(train_ds_grayscale)} samples in the Grayscale Training set')\n",
    "print(f'Using {count_samples(val_ds_grayscale)} samples in the Grayscale Validation set')\n",
    "print(f'Using {count_samples(test_ds_grayscale)} samples in the Grayscale Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = 'savedGrayDataset'\n",
    "\n",
    "tf.data.experimental.save(train_ds_grayscale, path_to_save + '/train')\n",
    "tf.data.experimental.save(val_ds_grayscale, path_to_save + '/val')\n",
    "tf.data.experimental.save(test_ds_grayscale, path_to_save + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_23 (Rescaling)    (None, 64, 64, 1)         0         \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 32, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 16, 16, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 8, 8, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 4, 4, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 4, 4, 128)        512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 2, 2, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_101 (Ba  (None, 2, 2, 128)        512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_110 (MaxPooli  (None, 1, 1, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307,058\n",
      "Trainable params: 306,162\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Grayscale CNN Model from Scratch\n",
    "def build_scratch_cnn_grayscale():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 1))) # Grayscale input shape\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "    \n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu',\n",
    "                            kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5)) \n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "scratch_model_grayscale = build_scratch_cnn_grayscale()\n",
    "scratch_model_grayscale.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2754/2754 [==============================] - 34s 12ms/step - loss: 2.7917 - accuracy: 0.1483 - val_loss: 2.5082 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 33s 12ms/step - loss: 1.9631 - accuracy: 0.4246 - val_loss: 1.6374 - val_accuracy: 0.5567\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 32s 12ms/step - loss: 1.5512 - accuracy: 0.5959 - val_loss: 1.6478 - val_accuracy: 0.5641\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 32s 12ms/step - loss: 1.3524 - accuracy: 0.6686 - val_loss: 1.2257 - val_accuracy: 0.7073\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 32s 11ms/step - loss: 1.2272 - accuracy: 0.7098 - val_loss: 1.2220 - val_accuracy: 0.7080\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 31s 11ms/step - loss: 1.1461 - accuracy: 0.7378 - val_loss: 1.1413 - val_accuracy: 0.7379\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 32s 12ms/step - loss: 1.0859 - accuracy: 0.7564 - val_loss: 1.1404 - val_accuracy: 0.7332\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 32s 12ms/step - loss: 1.0392 - accuracy: 0.7720 - val_loss: 1.2643 - val_accuracy: 0.6982\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 32s 11ms/step - loss: 1.0001 - accuracy: 0.7821 - val_loss: 1.1318 - val_accuracy: 0.7362\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 32s 12ms/step - loss: 0.9638 - accuracy: 0.7925 - val_loss: 1.1486 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "# Train Deep CNN Model\n",
    "history_grayscale = scratch_model_grayscale.fit(\n",
    "    train_ds_grayscale,\n",
    "    validation_data=val_ds_grayscale,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in history_grayscale.history.keys():\n",
    "    history_grayscale.history[key] = [float(i) for i in history_grayscale.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_grayscale.json', 'w') as f:\n",
    "    json.dump(history_grayscale.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model Grayscale: Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "scratch_model_grayscale.save('scratch_model_grayscale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "scratch_model_grayscale = load_model('scratch_model_grayscale.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN Model: Transfer Learning VGG-16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_TL = (64, 64)\n",
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE_TL[0], IMAGE_SIZE_TL[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transferlearning = tf.keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(IMAGE_SIZE_TL[0], IMAGE_SIZE_TL[1],3),\n",
    "    include_top=False)\n",
    "\n",
    "model_transferlearning.trainable = False\n",
    "x = data_augmentation_layers(inputs)\n",
    "x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "x = model_transferlearning(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes)(x)\n",
    "modeltf = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "modeltf.compile(\n",
    "                  optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2754/2754 [==============================] - 343s 124ms/step - loss: 4.9702 - accuracy: 0.2334 - val_loss: 2.5204 - val_accuracy: 0.3194\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 338s 123ms/step - loss: 2.8979 - accuracy: 0.2610 - val_loss: 2.5403 - val_accuracy: 0.3126\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 338s 123ms/step - loss: 2.9095 - accuracy: 0.2607 - val_loss: 2.5645 - val_accuracy: 0.3131\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 339s 123ms/step - loss: 2.9163 - accuracy: 0.2592 - val_loss: 2.4888 - val_accuracy: 0.3204\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 340s 123ms/step - loss: 2.9028 - accuracy: 0.2616 - val_loss: 2.5910 - val_accuracy: 0.3095\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 340s 123ms/step - loss: 2.9076 - accuracy: 0.2597 - val_loss: 2.5395 - val_accuracy: 0.3170\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 338s 123ms/step - loss: 2.9011 - accuracy: 0.2613 - val_loss: 2.5130 - val_accuracy: 0.3174\n"
     ]
    }
   ],
   "source": [
    "historytf = modeltf.fit(\n",
    "    train_ds,  \n",
    "    validation_data=(val_ds), \n",
    "    epochs=10, \n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any numpy types to Python lists\n",
    "for key in historytf.history.keys():\n",
    "    historytf.history[key] = [float(i) for i in historytf.history[key]]\n",
    "\n",
    "# Write the JSON file\n",
    "with open('cnn_model_vgg16.json', 'w') as f:\n",
    "    json.dump(historytf.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Deep CNN Model\n",
    "modeltf.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "modeltf = load_model('cnn_model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Camera**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming scratch_model_da2 and class_names are already defined elsewhere\n",
    "# cap is the VideoCapture object\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Adjust camera settings if needed\n",
    "cap.set(3, 480)  # Adjust width\n",
    "cap.set(4, 480)  # Adjust height\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Ensure that the frame was captured successfully before proceeding\n",
    "    if not success:\n",
    "        print(\"Error: Unable to capture video\")\n",
    "        break\n",
    "\n",
    "    # Resize the image to the desired size\n",
    "    imgsmall = cv2.resize(img, (128, 128))\n",
    "\n",
    "    # Prepare the image for prediction\n",
    "    image = np.array(imgsmall)\n",
    "    image = image.reshape(1, 128, 128, 3)\n",
    "\n",
    "    # Predict with your model\n",
    "    ans = scratch_model_deep.predict(image)\n",
    "    val = pd.DataFrame(ans, columns=class_names).idxmax(axis=1)\n",
    "\n",
    "    # Display the prediction on the image\n",
    "    cv2.putText(img, val.values[0], (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the webcam feed\n",
    "    cv2.imshow(\"Webcam\", img)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
