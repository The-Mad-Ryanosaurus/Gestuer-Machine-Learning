{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125912 files belonging to 18 classes.\n",
      "Using 88128 samples in the Training set\n",
      "Using 25184 samples in the Validation set\n",
      "Using 12600 samples in the Test set\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_4 (Sequential)   (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,122\n",
      "Trainable params: 290,226\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "2754/2754 [==============================] - 303s 109ms/step - loss: 1.6967 - accuracy: 0.4585 - val_loss: 1.1193 - val_accuracy: 0.6364\n",
      "Epoch 2/10\n",
      "2754/2754 [==============================] - 300s 109ms/step - loss: 0.8581 - accuracy: 0.7226 - val_loss: 0.7535 - val_accuracy: 0.7560\n",
      "Epoch 3/10\n",
      "2754/2754 [==============================] - 305s 111ms/step - loss: 0.6623 - accuracy: 0.7851 - val_loss: 0.5896 - val_accuracy: 0.8102\n",
      "Epoch 4/10\n",
      "2754/2754 [==============================] - 303s 110ms/step - loss: 0.5509 - accuracy: 0.8219 - val_loss: 0.4940 - val_accuracy: 0.8418\n",
      "Epoch 5/10\n",
      "2754/2754 [==============================] - 300s 109ms/step - loss: 0.4891 - accuracy: 0.8410 - val_loss: 0.5937 - val_accuracy: 0.8108\n",
      "Epoch 6/10\n",
      "2754/2754 [==============================] - 303s 110ms/step - loss: 0.4419 - accuracy: 0.8564 - val_loss: 0.5478 - val_accuracy: 0.8260\n",
      "Epoch 7/10\n",
      "2754/2754 [==============================] - 302s 110ms/step - loss: 0.4039 - accuracy: 0.8692 - val_loss: 0.4750 - val_accuracy: 0.8496\n",
      "Epoch 8/10\n",
      "2754/2754 [==============================] - 302s 110ms/step - loss: 0.3711 - accuracy: 0.8799 - val_loss: 0.4104 - val_accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "2754/2754 [==============================] - 303s 110ms/step - loss: 0.3500 - accuracy: 0.8862 - val_loss: 0.4157 - val_accuracy: 0.8665\n",
      "Epoch 10/10\n",
      "2754/2754 [==============================] - 303s 110ms/step - loss: 0.3236 - accuracy: 0.8941 - val_loss: 0.3976 - val_accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Set seed\n",
    "SEED = 338424\n",
    "\n",
    "# Global variables\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "num_classes = 18 # Number of folders in dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Define data augmentation layers\n",
    "data_augmentation_layers = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    #layers.RandomBrightness(0.1),\n",
    "    #layers.RandomContrast(0.1)\n",
    "])\n",
    "\n",
    "# Function to apply data augmentation only to training data\n",
    "def augment(image, label):\n",
    "    image = data_augmentation_layers(image)\n",
    "    return image, label\n",
    "\n",
    "# Load dataset\n",
    "dataset_dir = 'dataset/hagridset'\n",
    "full_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate sizes for each split\n",
    "total_size = len(full_ds)\n",
    "train_size = int(total_size * train_ratio)\n",
    "val_size = int(total_size * val_ratio)\n",
    "test_size = total_size - (train_size + val_size)\n",
    "\n",
    "# Prepare datasets\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Training set\n",
    "train_ds = (\n",
    "    full_ds.take(train_size)  # Take first N batches for training\n",
    "    .shuffle(train_size, seed=SEED)  # Shuffle the training set\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)  # Apply data augmentation\n",
    "    .cache()  # Cache the dataset to speed up subsequent epochs\n",
    "    .prefetch(buffer_size=AUTOTUNE)  # Prefetch data to reduce latency\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_ds = (\n",
    "    full_ds.skip(train_size)  # Skip training batches\n",
    "    .take(val_size)  # Take next N batches for validation\n",
    "    .cache()  # Cache validation data\n",
    "    .prefetch(buffer_size=AUTOTUNE)  # Prefetch data to reduce latency\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_ds = (\n",
    "    full_ds.skip(train_size + val_size)  # Skip training and validation batches\n",
    "    .cache()  # Cache test data\n",
    "    .prefetch(buffer_size=AUTOTUNE)  # Prefetch data to reduce latency\n",
    ")\n",
    "\n",
    "# Count samples in each subset\n",
    "def count_samples(dataset):\n",
    "    return sum(1 for _ in dataset.unbatch())\n",
    "\n",
    "print(f'Using {count_samples(train_ds)} samples in the Training set')\n",
    "print(f'Using {count_samples(val_ds)} samples in the Validation set')\n",
    "print(f'Using {count_samples(test_ds)} samples in the Test set')\n",
    "\n",
    "\n",
    "# Get class names\n",
    "class_names = full_ds.class_names\n",
    "class_names\n",
    "\n",
    "# Define your model with the data augmentation layer embedded\n",
    "def build_scratch_model_da2_cnn():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    model.add(data_augmentation_layers)\n",
    "    model.add(layers.Rescaling(1.0 / 255))  # Normalize pixel values\n",
    "\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "scratch_model_da2 = build_scratch_model_da2_cnn()\n",
    "scratch_model_da2.summary()\n",
    "\n",
    "# Train the model\n",
    "history_custom = scratch_model_da2.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 2s 4ms/step - loss: 0.5706 - accuracy: 0.8149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5706376433372498, 0.8149206638336182]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the CNN Data Augmentation Deep Model\n",
    "scratch_model_da2.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
